# Статьи по мультизадачным и мультимодальным моделям

Создание мультизадачных и мультимодальных моделей в настоящее время – активно развивающая сфера исследований, которая позволяет экономить вычислительные ресурсы и время, необходимое для обучения, а также впоследствии, возможно, приведет к созданию сильного искусственного интеллекта. 

1. [UniT: Multimodal Multitask Learning with a Unified Transformer](https://arxiv.org/pdf/2102.10772.pdf) (Unified Transformer (UniT), ```Hu, Singh, 2021```), который является частью фреймворка [MMF](https://github.com/facebookresearch/mmf) для построения мультимодальных моделей. В экспериментах UniT одновременно обучается на 8 датасетах (MS-COCO, VG, VQAv2, SNLI-VE, QNLI, MNLI-mm, QQP, SST-2) по 7 задачам (в текстовом, визуальном и совместном текстово-визуальном доменах). Модель имеет архитектуру типа «кодировщик-декодировщик» (encoder-decoder): для каждого типа данных (модальностей, в данном случае – текстовой и визуальной) используется свой кодировщик; декодировщик при этом единый для всех задач. Выход декодировщика отправляется в специфическую для конкретного задания «голову» (для всех задач, кроме object detection, она представляет собой двуслойный перцептрон), которая и выдаёт финальное предсказание:

<p align="center">
  <img src="https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/unit.png" width="70%">
</p>

При каждой итерации во время обучения для формирования батча выбирается задание и соответствующий ему датасет; для каждого задания заранее задаётся вероятность сэмплирования. 

2. [Multi-Task Deep Neural Network](https://github.com/namisan/mt-dnn) (MT-DNN, ```Liu, He et al., 2019```) – единая модель, созданная для решения различных задач в области понимания естественного языка (NLU). Нижние слои модели едины для всех задач, верхние слои специфичны для каждого типа задания. В качестве кодировщика используется многослойный двунаправленный кодировщик Трансформера – однако, в отличие от BERT, MT-DNN выучивает репрезентации не только с помощью предобучения, но и с помощью мультизадачных целевых функций. 
![image](https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/mt-dnn.png)
Процедура обучения MT-DNN состоит из двух стадий: предобучения и мультизадачного обучения. Во время мультизадачной фазы в каждую эпоху выбирается мини-батч (среди всех 9 заданий GLUE) – и веса модели обновляются согласно целевой функции, использующейся для конкретного задания. Такой подход аппроксимативно оптимизирует сумму целевых функций для всех задач. Авторы подчеркивают, что мультизадачное обучение имеет преимущества за счет эффекта регуляризации (меньший риск переобучения на конкретной задаче) – благодаря этому выученные репрезентации данных получаются более универсальными. MT-DNN обучалась на датасетах SNLI, SciTail и GLUE, решая 4 типа заданий: классификация единичных предложений, классификация пар текстов, оценка близости текстов, ранжирование текстов по релевантности.

3. [OmniNet: A unified architecture for multi-modal multi-task learning](https://arxiv.org/pdf/1907.07804.pdf) (`Pramanik et al., 2020`) — модель [OmniNet](https://github.com/subho406/OmniNet) включает два блока «периферических сетей» (peripheral networks): один кодирует картинки и видео, другой — текстовые данные. В качестве кодировщика изображений и видео используется предобученная сверточная нейросеть ResNet-152. Для кодирования текстов применяются предобученные подсловные эмбеддинги, полученные с помощью BPE. Закодированные данные конкатенируются с эмбеддингами типа данных и поступают в центральный блок (Central Neural Processor). Данные, у которых есть временная размерность, проходят через блок кодировщика; данные, у которых временной размерности нет, подвергаются преобразованию размерности (reshape). Все полученные матрицы сохраняются в кэш, который поступает в блок декодера:
![image](https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/omninet.png)
Предусмотрены эмбеддинги заданий, несколько наборов выходных эмбеддинов для разных типов выходных данных и отдельные классификаторы для разных заданий. Мультизадачность достигается с помощью подхода HogWild: помимо глобальной копии модели, создаются локальные копии для каждого задания; вычисленные локальные градиенты асинхронно копируются в глобальную модель, затем происходит обновление её весов. Модель обучалась на задачах частеречной разметки, генерации ответов на вопросы по изображению, генерации подписей к картинкам и распознавания действий на видео.

4. [12-in-1: Multi-Task Vision and Language Representation Learning](https://arxiv.org/pdf/1912.02315.pdf) (`Lu, Goswami et al., 2020`) — в статье описывается модель, основанная на архитектуре [ViLBERT](https://arxiv.org/pdf/1908.02265.pdf) (`Lu et al., 2019`), в которой текстовые и визуальные входные данные взаимодействуют посредством слоёв co-attention (механизма "взаимного внимания"):
![image](https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/vilbert.png)
Изображение и текст, к которым добавляется соответствующий заданию токен, кодируются с помощью двух блоков, архитектура которых подобна BERT. Эти модули предобучены на задачах предсказания маскированного элемента и предсказания наличия связи между входными данными. Авторы использовали 12 датасетов с задачами, основанных на изображениях и текстах. Эти задачи можно разделить на следующие группы: выбор подходящего ответа на вопрос по изображению, выбор изображения, соответствующего описанию, выбор фрагмента изображения, соответствующего описанию, проверка, соответствуют ли друг другу изображение и текст Для решения этих задач обучено шесть голов модели. При обучении используется предложенный авторами метод stop-and-go, позволяющий приоставливать использование датасетов небольшого объема на большее количество итераций и продолжать использовать большие датасеты. 

5. [M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training](https://arxiv.org/pdf/2006.02635.pdf) (`Ni et al., 2021`) — модель, в которой мультилингвальное предобучение и мультимодальное предобучение комбинируются с помощью мультизадачности в едином фреймворке:
![image](https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/m3p.png)
Мультизадачность интегрирована в стадию предобучения для одновременной оптимизации всех выбранных целевых функций. Сначала модель предобучается на задаче предсказания маскированного токена, при этом используются три типа входных данных: текст на одном языке + изображения; текст, в котором происходит смена языка (Multimodal Code-switched Training); сочетание первых двух случаев. Далее модель дообучается на двух мультилингвальных датасетах, используемых для задачи поиска изображений: Multi30K — расширенная версия Flickr30K (английские, немецкие, французские и чешские подписи) and MS-COCO (английские, китайские и японские подписи). 

6. [HyperGrid Transformers: Towards A Single Model for Multiple Tasks](https://openreview.net/pdf?id=hiq1rHO8pNT) – авторы предлагают подход, при котором мультизадачное обучение модели обеспечивается благодаря использованию декомпозиционной гиперсети (сети, которая генерирует веса для основной модели), которая выучивает grid-wise проекции, позволяющие выделять отдельные регионы в матрице весов в зависимости от задачи, обеспечивая специализацию подсети. Для построения подобной гиперсети используются локальная (зависящая от примера и задачи) и глобальная (независимая от задачи) проекции: композиция локального и глобального векторов формирует матрицу гейтирования, которая затем расширяется (повтором) до размера матрицы весов Трансформера для получения специфичной для каждого задания матрицы весов:
![image](https://dsworks.s3pd01.sbercloud.ru/aij2021/misc/hypergrid.png)
Авторы проводили эксперименты на бенчмарках GLUE и SuperGLUE (задачи NLP и NLU). В качестве основной модели используется T5, к ней добавляются слои HyperGrid. Результаты демонстрируют, что качество единой модели (Avg 85.0 на GLUE и 73.6 на SuperGLUE) не намного уступает качеству отдельных моделей, дообученных под конкретные задачи (Avg 85.7 на GLUE и 74.8 на SuperGLUE), однако обучение единой архитектуры требует изменения в 16 раз меньшего количества параметров.  
